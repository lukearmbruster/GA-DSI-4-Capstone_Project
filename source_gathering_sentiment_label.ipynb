{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as tkr\n",
    "import pickle\n",
    "import urllib2\n",
    "import json\n",
    "import datetime\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import sqlite3\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the following facebook page post scraper was taken from \n",
    "# https://drive.google.com/file/d/0Bw1LIIbSl0xuRTNCZElUa3U1b1U/view\n",
    "\n",
    "# study period from August 26, 2016 to January 20, 2017 (includes 73 between election day)\n",
    "app_id = \"1239416149446116\"\n",
    "app_secret = \"b75da335f4fab048c1564a066b4848ba\" # DO NOT SHARE WITH ANYONE!\n",
    "\n",
    "access_token = app_id + \"|\" + app_secret\n",
    "\n",
    "#access_token = raw_input(\"Please Paste Your Access Token:\")\n",
    "\n",
    "def request_until_succeed(url):\n",
    "    req = urllib2.Request(url)\n",
    "    success = False\n",
    "    while success is False:\n",
    "        try: \n",
    "            response = urllib2.urlopen(req)\n",
    "            if response.getcode() == 200:\n",
    "                success = True\n",
    "        except Exception, e:\n",
    "            print e\n",
    "            time.sleep(5)\n",
    "\n",
    "            print \"Error for URL %s: %s\" % (url, datetime.datetime.now())\n",
    "            print \"Retrying.\"\n",
    "\n",
    "    return response.read()\n",
    "\n",
    "# Needed to write tricky unicode correctly to csv\n",
    "def unicode_normalize(text):\n",
    "    return text.translate({ 0x2018:0x27, 0x2019:0x27, 0x201C:0x22, 0x201D:0x22,\n",
    "                            0xa0:0x20 }).encode('utf-8')\n",
    "\n",
    "def getFacebookPageFeedData(page_id, access_token, num_statuses):\n",
    "\n",
    "    base = \"https://graph.facebook.com/v2.6\"\n",
    "    node = \"/%s/posts\" % page_id \n",
    "    fields = \"/?fields=message,link,permalink_url,created_time,type,name,id,\" + \\\n",
    "            \"comments.limit(0).summary(true),shares,reactions\" + \\\n",
    "            \".limit(0).summary(true)\"\n",
    "    parameters = \"&until=2017-01-21&since=2016-08-25&limit=%s&access_token=%s\" % (num_statuses, access_token)\n",
    "    \n",
    "    url = base + node + fields + parameters\n",
    "\n",
    "    # retrieve data\n",
    "    \n",
    "    data = json.loads(request_until_succeed(url))\n",
    "    return data\n",
    "\n",
    "def getReactionsForStatus(status_id, access_token):\n",
    "    base = \"https://graph.facebook.com/v2.6\"\n",
    "    node = \"/%s\" % status_id\n",
    "    reactions = \"/?fields=\" \\\n",
    "            \"reactions.type(LIKE).limit(0).summary(total_count).as(like)\" \\\n",
    "            \",reactions.type(LOVE).limit(0).summary(total_count).as(love)\" \\\n",
    "            \",reactions.type(WOW).limit(0).summary(total_count).as(wow)\" \\\n",
    "            \",reactions.type(HAHA).limit(0).summary(total_count).as(haha)\" \\\n",
    "            \",reactions.type(SAD).limit(0).summary(total_count).as(sad)\" \\\n",
    "            \",reactions.type(ANGRY).limit(0).summary(total_count).as(angry)\"\n",
    "    parameters = \"&until=2017-01-21&since=2016-08-25&access_token=%s\" % access_token\n",
    "    url = base + node + reactions + parameters\n",
    "\n",
    "    # retrieve data\n",
    "    data = json.loads(request_until_succeed(url))\n",
    "     \n",
    "    return data\n",
    "\n",
    "def processFacebookPageFeedStatus(status, access_token):\n",
    "\n",
    "    # The status is now a Python dictionary, so for top-level items,\n",
    "    # we can simply call the key.\n",
    "\n",
    "    # Additionally, some items may not always exist,\n",
    "    # so must check for existence first\n",
    "\n",
    "    status_id = status['id']\n",
    "    status_message = '' if 'message' not in status.keys() else \\\n",
    "            unicode_normalize(status['message'])\n",
    "    link_name = '' if 'name' not in status.keys() else \\\n",
    "            unicode_normalize(status['name'])\n",
    "    status_type = status['type']\n",
    "    status_link = '' if 'link' not in status.keys() else \\\n",
    "            unicode_normalize(status['link'])\n",
    "    status_permalink_url = '' if 'permalink_url' not in status.keys() else \\\n",
    "            unicode_normalize(status['permalink_url'])\n",
    "    # Time needs special care since a) it's in UTC and\n",
    "    # b) it's not easy to use in statistical programs.\n",
    "\n",
    "    status_published = datetime.datetime.strptime(\n",
    "            status['created_time'],'%Y-%m-%dT%H:%M:%S+0000')\n",
    "    status_published = status_published + \\\n",
    "            datetime.timedelta(hours=-8) # PST\n",
    "    status_published = status_published.strftime(\n",
    "            '%Y-%m-%d %H:%M:%S') # best time format for spreadsheet programs\n",
    "\n",
    "    # Nested items require chaining dictionary keys.\n",
    "\n",
    "    num_reactions = 0 if 'reactions' not in status else \\\n",
    "            status['reactions']['summary']['total_count']\n",
    "    num_comments = 0 if 'comments' not in status else \\\n",
    "            status['comments']['summary']['total_count']\n",
    "    num_shares = 0 if 'shares' not in status else status['shares']['count']\n",
    "\n",
    "    # Counts of each reaction separately; good for sentiment\n",
    "    # Only check for reactions if past date of implementation:\n",
    "    # http://newsroom.fb.com/news/2016/02/reactions-now-available-globally/\n",
    "\n",
    "    reactions = getReactionsForStatus(status_id, access_token) if \\\n",
    "            status_published > '2016-02-24 00:00:00' else {}\n",
    "\n",
    "    num_likes = 0 if 'like' not in reactions else \\\n",
    "            reactions['like']['summary']['total_count']\n",
    "\n",
    "    # Special case: Set number of Likes to Number of reactions for pre-reaction\n",
    "    # statuses\n",
    "\n",
    "    num_likes = num_reactions if status_published < '2016-02-24 00:00:00' \\\n",
    "            else num_likes\n",
    "\n",
    "    def get_num_total_reactions(reaction_type, reactions):\n",
    "        if reaction_type not in reactions:\n",
    "            return 0\n",
    "        else:\n",
    "            return reactions[reaction_type]['summary']['total_count']\n",
    "\n",
    "    num_loves = get_num_total_reactions('love', reactions)\n",
    "    num_wows = get_num_total_reactions('wow', reactions)\n",
    "    num_hahas = get_num_total_reactions('haha', reactions)\n",
    "    num_sads = get_num_total_reactions('sad', reactions)\n",
    "    num_angrys = get_num_total_reactions('angry', reactions)\n",
    "\n",
    "    # Return a tuple of all processed data\n",
    "\n",
    "    return (status_id, status_message, link_name, status_type, status_link, status_permalink_url,\n",
    "            status_published, num_reactions, num_comments, num_shares,\n",
    "            num_likes, num_loves, num_wows, num_hahas, num_sads, num_angrys)\n",
    "\n",
    "\n",
    "def scrapeFacebookPageFeedStatus(page_id, access_token):\n",
    "    with open('%s_facebook_statuses.csv' % page_id, 'wb') as file:\n",
    "        w = csv.writer(file)\n",
    "        w.writerow([\"status_id\", \"status_message\", \"link_name\", \"status_type\",\n",
    "                    \"status_link\", \"permalink_url\", \"status_published\", \"num_reactions\", \n",
    "                    \"num_comments\", \"num_shares\", \"num_likes\", \"num_loves\", \n",
    "                    \"num_wows\", \"num_hahas\", \"num_sads\", \"num_angrys\"])\n",
    "\n",
    "        has_next_page = True\n",
    "        num_processed = 0   # keep a count on how many we've processed\n",
    "        scrape_starttime = datetime.datetime.now()\n",
    "\n",
    "        print \"Scraping %s Facebook Page: %s\\n\" % (page_id, scrape_starttime)\n",
    "\n",
    "        statuses = getFacebookPageFeedData(page_id, access_token, 100)\n",
    "\n",
    "        while has_next_page:\n",
    "            for status in statuses['data']:\n",
    "                # Ensure it is a status with the expected metadata\n",
    "                if 'reactions' in status:\n",
    "                    w.writerow(processFacebookPageFeedStatus(status,\n",
    "                        access_token))\n",
    "\n",
    "                # output progress occasionally to make sure code is not\n",
    "                # stalling\n",
    "                num_processed += 1\n",
    "                if num_processed % 100 == 0:\n",
    "                    print \"%s Statuses Processed: %s\" % \\\n",
    "                        (num_processed, datetime.datetime.now())\n",
    "\n",
    "            # if there is no next page, we're done.\n",
    "            if ('paging' in statuses.keys()):\n",
    "                statuses = json.loads(request_until_succeed(\n",
    "                                        statuses['paging']['next']))\n",
    "            else:\n",
    "                has_next_page = False\n",
    "\n",
    "\n",
    "        print \"\\nDone!\\n%s Statuses Processed in %s\" % \\\n",
    "                (num_processed, datetime.datetime.now() - scrape_starttime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABCNews', 'CBSNews', 'FoxNews', 'NPR', 'cnn', 'msnbc', 'newshour', 'newyorker', 'nytimes', 'usatoday', 'washingtonpost', 'wsj', 'yahoonews']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# mainstream sources trusted more than not according to Pew study\n",
    "\n",
    "mainstream=[\"nytimes\", \"wsj\", \"ABCNews\", \"CBSNews\", \"cnn\",\"usatoday\", \"washingtonpost\",\n",
    "           \"msnbc\",\"newyorker\",\"yahoonews\",\"FoxNews\", \"NPR\", \"newshour\"]\n",
    "print sorted(mainstream)\n",
    "print len(mainstream)\n",
    "# for news in mainstream:\n",
    "#     page_id=news\n",
    "#     scrapeFacebookPageFeedStatus(page_id, access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['24Newsflash', 'ClashDaily', 'DHeadlines', 'DcGazette', 'DonaldTrumpNews.Co', 'EmpireNewsNet', 'FreedomDailyNews', 'FreshNews000', 'LastGreatStand', 'NewsWithViews', 'Newslo1', 'OnlineConservativePress', 'RHobbusJD', 'RickRWells', 'StormCloudsGathering', 'TheAdoboChronicles', 'TheRightists', 'TheUndergroundWorldNews', 'ThreePercenterNation', 'USPoliticsLive', 'beforeitsnewscom', 'conservativebyte', 'conservativeinfidel', 'downtrendcom', 'eutopiabuzz', 'hmakow', 'intrendtoday', 'newsexaminer.net', 'newswatch28', 'pakalertpress', 'politicalsitenews', 'prntly', 'proudcons', 'rilenews', 'subjectpolitics', 'supremepatriot', 'usanewsoftheday', 'usasupreme', 'weeklyworldnews', 'worldrumor', 'worldstoriestoday', 'yesiamright']\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "# doesn't work: 'conservativegroup', \n",
    "# done:  \n",
    "fake=['worldrumor',\n",
    "     'newswatch28','FreshNews000','TheRightists','subjectpolitics', 'weeklyworldnews', 'USPoliticsLive',\n",
    "     'DcGazette','FreedomDailyNews','EmpireNewsNet','Newslo1','NewsWithViews','supremepatriot',\n",
    "     'StormCloudsGathering', 'DHeadlines', 'newsexaminer.net','24Newsflash','LastGreatStand','eutopiabuzz',\n",
    "     'conservativeinfidel','ThreePercenterNation','TheUndergroundWorldNews','RHobbusJD',\n",
    "     'downtrendcom','intrendtoday','ClashDaily','worldstoriestoday','TheAdoboChronicles','beforeitsnewscom', \n",
    "      'DonaldTrumpNews.Co', 'hmakow', 'pakalertpress','usasupreme','rilenews', 'RickRWells', 'usanewsoftheday',\n",
    "      'yesiamright', 'proudcons', 'conservativebyte','politicalsitenews', 'prntly', 'OnlineConservativePress']\n",
    "print sorted(fake)\n",
    "print len(fake)\n",
    "\n",
    "# for news in fake:\n",
    "#     page_id=news\n",
    "#     scrapeFacebookPageFeedStatus(page_id, access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21WIRE.TV', 'AwarenessAct', 'BradleeDeanSOL', 'CanadaFreePress', 'DisclosureMedia', 'EyeOpeningInfo', 'FourWinds10', 'Gaia', 'GlobalResearchCRG', 'HumansAreFree', 'LibertyMovementRadio', 'LibertyTalkFM', 'NewsTargetOfficial', 'NowTheEndBegins', 'SECRETSofTheFED', 'SilverCoinInvestor', 'TheCorbettReport', 'TheLibertyBeaconProject', 'TheMindUnleashed', 'ThePoliticalInsider', 'TheSilverDoctors', 'TruthBroadcastNetworkcom', 'activistpost', 'adeptoerperfectus', 'americanfreepress', 'atsnews', 'concisepolitics', 'conservativerefocusgroup', 'fprnradio', 'freedomoutpost', 'godlikeproductions', 'govtslaves', 'intelligencehub', 'investmentresearchdynamics', 'pamelageller', 'skeptiko.us', 'thedailysheeple', 'theeventhandbook', 'theprepperwebsite', 'truth.frequency.radio', 'ufoholics', 'zerohedge1']\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "# Can not use: 'WorldTruthTV','zootfeednews',\n",
    "conspiracy=['pamelageller','fprnradio','americanfreepress','LibertyTalkFM','TheMindUnleashed','adeptoerperfectus', \n",
    "            'Gaia','conservativerefocusgroup','CanadaFreePress','concisepolitics','FourWinds10','ThePoliticalInsider',\n",
    "            'DisclosureMedia','TheSilverDoctors','skeptiko.us','21WIRE.TV','atsnews','activistpost','TheCorbettReport',\n",
    "            'EyeOpeningInfo','freedomoutpost','GlobalResearchCRG','godlikeproductions','govtslaves','HumansAreFree',\n",
    "            'investmentresearchdynamics','intelligencehub','NewsTargetOfficial','NowTheEndBegins','theprepperwebsite',\n",
    "            'SECRETSofTheFED','thedailysheeple','theeventhandbook','TruthBroadcastNetworkcom',\n",
    "            'truth.frequency.radio','ufoholics','zerohedge1','SilverCoinInvestor','LibertyMovementRadio',\n",
    "            'BradleeDeanSOL','TheLibertyBeaconProject','AwarenessAct']\n",
    "print sorted(conspiracy)\n",
    "print len(conspiracy)\n",
    "\n",
    "# for news in conspiracy:\n",
    "#     page_id=news\n",
    "#     scrapeFacebookPageFeedStatus(page_id, access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BeehiveBugle', 'BurrardStreetJournal', 'CallTheCopsNews', 'CreamBmp', 'FreeWoodPost', 'FridayMash', 'Gomerblog', 'HumorTimes', 'LiberalBiasBlog', 'NewsBiscuit', 'NewsThump', 'NewsToad', 'Reductress', 'RockCityTimes', 'SatiraTribune', 'SportsPickle', 'TheBeaverton', 'TheCelebtricity', 'TheHolyObserver', 'TheMadisonMisnomer', 'TheNewsNerd', 'TheOnion', 'TheSkunkPage', 'TheStatelyHarold', 'WhispersNews', 'abril.uno.satire', 'associatedmediacoverage', 'betootaadvocate', 'blastingusa', 'clickhole', 'dailycurrant', 'disclosetv', 'elkoshary', 'elmundotoday', 'goingwunderground', 'islamicanews', 'liberaldarkness', 'stuppidcom', 'thedandygoat', 'thehardtimesnews', 'theineptowl', 'thetimesoftheworld', 'theunrealpage', 'witscience', 'worldnewsdailyreport']\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "# Can not use: ncscooper, 'NationalReportOnline',\n",
    "satire=['TheHolyObserver','CallTheCopsNews','NewsToad',\n",
    "        'associatedmediacoverage','LiberalBiasBlog','dailycurrant','theineptowl','betootaadvocate','clickhole','disclosetv', 'elmundotoday', 'Gomerblog','NewsBiscuit',\n",
    "       'NewsThump','Reductress','TheOnion','theunrealpage','WhispersNews','goingwunderground','FreeWoodPost',\n",
    "       'thetimesoftheworld','worldnewsdailyreport','BeehiveBugle','thedandygoat','RockCityTimes',\n",
    "       'CreamBmp','TheMadisonMisnomer','liberaldarkness','abril.uno.satire','TheStatelyHarold','SportsPickle',\n",
    "       'TheSkunkPage','stuppidcom','witscience','SatiraTribune','HumorTimes','TheNewsNerd','blastingusa',\n",
    "       'elkoshary','islamicanews','BurrardStreetJournal','thehardtimesnews','TheBeaverton','FridayMash',\n",
    "       'TheCelebtricity']\n",
    "print sorted(satire)\n",
    "print len(satire)\n",
    "\n",
    "# for news in satire:\n",
    "#     page_id=news\n",
    "#     scrapeFacebookPageFeedStatus(page_id, access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Further analysis from main notebook, separated to conduct multiple analyses simulaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlite_db = '/Users/lukejarmbruster/Desktop/DSI-SF-4-larmbruster/projects/capstone/facebook_news.sqlite'\n",
    "conn = sqlite3.connect(sqlite_db) \n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fb_news_total=pd.read_sql('SELECT * FROM fbook_news', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert object columns from unicode to string\n",
    "def decoder(x):\n",
    "    if not x:\n",
    "        return ''\n",
    "    else:\n",
    "        x_ = ''.join([ch for ch in x if ch in string.printable])\n",
    "        return str(x_.decode('ascii'))\n",
    "object_types=fb_news_total.columns[fb_news_total.dtypes=='object']\n",
    "for i in object_types:\n",
    "    fb_news_total[i] = fb_news_total[i].map(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fb_news_total.status_published=pd.to_datetime(fb_news_total.status_published)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# study period from August 26, 2016 [including] to January 19, 2017 [including ](includes 73 \n",
    "# before and after election day)\n",
    "\n",
    "mask=((fb_news_total['status_published'] >= '2016-08-26') & (fb_news_total['status_published'] < '2017-01-20')) \n",
    "fb_news_total=fb_news_total.loc[mask]\n",
    "fb_news_total['election_day']='same'\n",
    "fb_news_total.ix[fb_news_total['status_published']<'2016-11-07','election_day']='before'\n",
    "fb_news_total.ix[fb_news_total['status_published']>='2016-11-08','election_day']='after'\n",
    "fb_news_total.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#fb_news_total.ix[fb_news_total['election_day']=='same','status_published'].sort_values()\n",
    "del mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add time columns\n",
    "fb_news_total['day_of_week']=fb_news_total.status_published.dt.weekday_name\n",
    "fb_news_total['year']=fb_news_total.status_published.dt.year\n",
    "fb_news_total['month']=fb_news_total.status_published.dt.month\n",
    "fb_news_total['day']=fb_news_total.status_published.dt.day\n",
    "fb_news_total['hour']=fb_news_total.status_published.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "274618\n"
     ]
    }
   ],
   "source": [
    "# investigate repeats in status_id, status_message, link_name, status_link, permalink_url\n",
    "# removed duplicate posts\n",
    "mask=((fb_news_total.duplicated(['status_id'])) & (fb_news_total.duplicated(['status_message'])) & \n",
    "      (fb_news_total.duplicated(['link_name'])) & (fb_news_total.duplicated(['status_link'])) &\n",
    "      (fb_news_total.duplicated(['permalink_url'])) & (fb_news_total.duplicated(['status_published']))\n",
    "     & (fb_news_total.duplicated(['num_reactions'])))\n",
    "\n",
    "print sum(mask)\n",
    "print sum(~mask)\n",
    "\n",
    "# remove the rows with that repeat six of the same columns elements as another row\n",
    "fb_news_total=fb_news_total[~mask]\n",
    "fb_news_total.reset_index(inplace=True, drop=True)\n",
    "del mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fb_news_total['all_interactions']=fb_news_total['num_reactions']+fb_news_total['num_shares']+fb_news_total['num_comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from spacy import en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addstop=['bz', 'rgn', 'ly','000','li','ws','ow','pos','\\n','\"','2g8inr1','20170113','2evy5ku','abcn','clickhole']\n",
    "for i in addstop:\n",
    "    en.STOPWORDS.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our photographer Doug Mills has taken \"hundreds of thousands\" of photos of Barack Obama. \"He wears his emotions on his sleeve,\" he said. \"You can see when he\\'s tense. Or jovial. The passion is there.\"'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_news_total['status_message'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean text\n",
    "#len(fb_news_total['status_message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(fb_news_total['status_message'])):\n",
    "    fb_news_total.ix[i,'status_message']=re.sub(r'[-a-zA-Z0-9@:%_\\+.~#?&//=]{2,256}\\.[a-z]{2,4}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)?', ' ', fb_news_total.ix[i,'status_message'])\n",
    "    fb_news_total.ix[i,'status_message']=re.sub(r'\\/', ' ', fb_news_total.ix[i,'status_message'])\n",
    "    fb_news_total.ix[i,'status_message']=re.sub('/n', ' ', fb_news_total.ix[i,'status_message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "fb_news_total['sentiment_comp_score']=None\n",
    "for i in range(len(fb_news_total['status_message'])):\n",
    "    sentences=sent_tokenize(fb_news_total.ix[i,'status_message'])\n",
    "    templist=[]\n",
    "    for j in sentences:\n",
    "        try:\n",
    "            single_score = analyzer.polarity_scores(j)\n",
    "            templist.append(single_score['compound'])\n",
    "            print j\n",
    "            print single_score\n",
    "            print \"\"\n",
    "        except:\n",
    "            # writing to a file with pickle\n",
    "            # 'w' is for write, note that it will rewrite any existing obj\n",
    "            if len(templist)==0:\n",
    "                fb_news_total.ix[i,'sentiment_comp_score']=None\n",
    "            else:\n",
    "                fb_news_total.ix[i,'sentiment_comp_score']=np.mean(templist)\n",
    "            with open('/Users/lukejarmbruster/Desktop/DSI-SF-4-larmbruster/projects/capstone/sentiment_output_clean.pkl', 'w') as f:\n",
    "                pickle.dump(fb_news_total, f)\n",
    "            pass\n",
    "    if len(templist)==0:\n",
    "        fb_news_total.ix[i,'sentiment_comp_score']=None\n",
    "    else:\n",
    "        fb_news_total.ix[i,'sentiment_comp_score']=np.mean(templist)\n",
    "\n",
    "with open('/Users/lukejarmbruster/Desktop/DSI-SF-4-larmbruster/projects/capstone/sentiment_output_clean.pkl', 'w') as f:\n",
    "    pickle.dump(fb_news_total, f)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
